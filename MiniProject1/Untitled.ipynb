{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.nn.functional import elu\n",
    "from braindecode.torch_ext.modules import Expression, AvgPool2dWithConv\n",
    "from braindecode.torch_ext.functions import identity\n",
    "from braindecode.torch_ext.util import np_to_var\n",
    "\n",
    "\n",
    "class Deep4Net(object):\n",
    "    \"\"\"\n",
    "    Deep ConvNet model from [1]_.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Schirrmeister, R. T., Springenberg, J. T., Fiederer, L. D. J., \n",
    "       Glasstetter, M., Eggensperger, K., Tangermann, M., ... & Ball, T. (2017).\n",
    "       Deep learning with convolutional neural networks for EEG decoding and\n",
    "       visualization.\n",
    "       arXiv preprint arXiv:1703.05051.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_chans,\n",
    "                 n_classes,\n",
    "                 input_time_length,\n",
    "                 final_conv_length,\n",
    "                 n_filters_time=25,\n",
    "                 n_filters_spat=25,\n",
    "                 filter_time_length=10,\n",
    "                 pool_time_length=3,\n",
    "                 pool_time_stride=3,\n",
    "                 n_filters_2=50,\n",
    "                 filter_length_2=10,\n",
    "                 n_filters_3=100,\n",
    "                 filter_length_3=10,\n",
    "                 n_filters_4=200,\n",
    "                 filter_length_4=10,\n",
    "                 first_nonlin=elu,\n",
    "                 first_pool_mode='max',\n",
    "                 first_pool_nonlin=identity,\n",
    "                 later_nonlin=elu,\n",
    "                 later_pool_mode='max',\n",
    "                 later_pool_nonlin=identity,\n",
    "                 drop_prob=0.5,\n",
    "                 double_time_convs=False,\n",
    "                 split_first_layer=True,\n",
    "                 batch_norm=True,\n",
    "                 batch_norm_alpha=0.1,\n",
    "                 stride_before_pool=False):\n",
    "        if final_conv_length == 'auto':\n",
    "            assert input_time_length is not None\n",
    "\n",
    "        self.__dict__.update(locals())\n",
    "        del self.self\n",
    "\n",
    "    def create_network(self):\n",
    "        if self.stride_before_pool:\n",
    "            conv_stride = self.pool_time_stride\n",
    "            pool_stride = 1\n",
    "        else:\n",
    "            conv_stride = 1\n",
    "            pool_stride = self.pool_time_stride\n",
    "        pool_class_dict = dict(max=nn.MaxPool2d, mean=AvgPool2dWithConv)\n",
    "        first_pool_class = pool_class_dict[self.first_pool_mode]\n",
    "        later_pool_class = pool_class_dict[self.later_pool_mode]\n",
    "        model = nn.Sequential()\n",
    "        if self.split_first_layer:\n",
    "            model.add_module('dimshuffle', Expression(_transpose_time_to_spat))\n",
    "            model.add_module('conv_time', nn.Conv2d(1, self.n_filters_time,\n",
    "                                                    (\n",
    "                                                    self.filter_time_length, 1),\n",
    "                                                    stride=1, ))\n",
    "            model.add_module('conv_spat',\n",
    "                             nn.Conv2d(self.n_filters_time, self.n_filters_spat,\n",
    "                                       (1, self.in_chans),\n",
    "                                       stride=(conv_stride, 1),\n",
    "                                       bias=not self.batch_norm))\n",
    "            n_filters_conv = self.n_filters_spat\n",
    "        else:\n",
    "            model.add_module('conv_time',\n",
    "                             nn.Conv2d(self.in_chans, self.n_filters_time,\n",
    "                                       (self.filter_time_length, 1),\n",
    "                                       stride=(conv_stride, 1),\n",
    "                                       bias=not self.batch_norm))\n",
    "            n_filters_conv = self.n_filters_time\n",
    "        if self.batch_norm:\n",
    "            model.add_module('bnorm',\n",
    "                             nn.BatchNorm2d(n_filters_conv,\n",
    "                                            momentum=self.batch_norm_alpha,\n",
    "                                            affine=True,\n",
    "                                            eps=1e-5),)\n",
    "        model.add_module('conv_nonlin', Expression(self.first_nonlin))\n",
    "        model.add_module('pool',\n",
    "                         first_pool_class(\n",
    "                             kernel_size=(self.pool_time_length, 1),\n",
    "                             stride=(pool_stride, 1)))\n",
    "        model.add_module('pool_nonlin', Expression(self.first_pool_nonlin))\n",
    "\n",
    "        def add_conv_pool_block(model, n_filters_before,\n",
    "                                n_filters, filter_length, block_nr):\n",
    "            suffix = '_{:d}'.format(block_nr)\n",
    "            model.add_module('drop' + suffix,\n",
    "                             nn.Dropout(p=self.drop_prob))\n",
    "            model.add_module('conv' + suffix.format(block_nr),\n",
    "                             nn.Conv2d(n_filters_before, n_filters,\n",
    "                                       (filter_length, 1),\n",
    "                                       stride=(conv_stride, 1),\n",
    "                                       bias=not self.batch_norm))\n",
    "            if self.batch_norm:\n",
    "                model.add_module('bnorm' + suffix,\n",
    "                             nn.BatchNorm2d(n_filters,\n",
    "                                            momentum=self.batch_norm_alpha,\n",
    "                                            affine=True,\n",
    "                                            eps=1e-5))\n",
    "            model.add_module('nonlin' + suffix,\n",
    "                             Expression(self.later_nonlin))\n",
    "\n",
    "            model.add_module('pool' + suffix,\n",
    "                             later_pool_class(\n",
    "                                 kernel_size=(self.pool_time_length, 1),\n",
    "                                 stride=(pool_stride, 1)))\n",
    "            model.add_module('pool_nonlin' + suffix,\n",
    "                             Expression(self.later_pool_nonlin))\n",
    "\n",
    "        add_conv_pool_block(model, n_filters_conv, self.n_filters_2,\n",
    "                            self.filter_length_2, 2)\n",
    "        add_conv_pool_block(model, self.n_filters_2, self.n_filters_3,\n",
    "                            self.filter_length_3, 3)\n",
    "        add_conv_pool_block(model, self.n_filters_3, self.n_filters_4,\n",
    "                            self.filter_length_4, 4)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        if self.final_conv_length == 'auto':\n",
    "            out = model(np_to_var(np.ones(\n",
    "                (1, self.in_chans, self.input_time_length,1),\n",
    "                dtype=np.float32)))\n",
    "            n_out_time = out.cpu().data.numpy().shape[2]\n",
    "            self.final_conv_length = n_out_time\n",
    "        model.add_module('conv_classifier',\n",
    "                             nn.Conv2d(self.n_filters_4, self.n_classes,\n",
    "                                       (self.final_conv_length, 1), bias=True))\n",
    "        model.add_module('softmax', nn.LogSoftmax())\n",
    "        model.add_module('squeeze',  Expression(_squeeze_final_output))\n",
    "\n",
    "        # Initialization, xavier is same as in our paper...\n",
    "        # was default from lasagne\n",
    "        init.xavier_uniform(model.conv_time.weight, gain=1)\n",
    "        # maybe no bias in case of no split layer and batch norm\n",
    "        if self.split_first_layer or (not self.batch_norm):\n",
    "            init.constant(model.conv_time.bias, 0)\n",
    "        if self.split_first_layer:\n",
    "            init.xavier_uniform(model.conv_spat.weight, gain=1)\n",
    "            if not self.batch_norm:\n",
    "                init.constant(model.conv_spat.bias, 0)\n",
    "        if self.batch_norm:\n",
    "            init.constant(model.bnorm.weight, 1)\n",
    "            init.constant(model.bnorm.bias, 0)\n",
    "        param_dict = dict(list(model.named_parameters()))\n",
    "        for block_nr in range(2,5):\n",
    "            conv_weight = param_dict['conv_{:d}.weight'.format(block_nr)]\n",
    "            init.xavier_uniform(conv_weight, gain=1)\n",
    "            if not self.batch_norm:\n",
    "                conv_bias = param_dict['conv_{:d}.bias'.format(block_nr)]\n",
    "                init.constant(conv_bias, 0)\n",
    "            else:\n",
    "                bnorm_weight = param_dict['bnorm_{:d}.weight'.format(block_nr)]\n",
    "                bnorm_bias = param_dict['bnorm_{:d}.bias'.format(block_nr)]\n",
    "                init.constant(bnorm_weight, 1)\n",
    "                init.constant(bnorm_bias, 0)\n",
    "\n",
    "        init.xavier_uniform(model.conv_classifier.weight, gain=1)\n",
    "        init.constant(model.conv_classifier.bias, 0)\n",
    "\n",
    "        # Start in eval mode\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "\n",
    "# remove empty dim at end and potentially remove empty time dim\n",
    "# do not just use squeeze as we never want to remove first dim\n",
    "def _squeeze_final_output(x):\n",
    "    assert x.size()[3] == 1\n",
    "    x = x[:,:,:,0]\n",
    "    if x.size()[2] == 1:\n",
    "        x = x[:,:,0]\n",
    "    return x\n",
    "\n",
    "\n",
    "def _transpose_time_to_spat(x):\n",
    "    return x.permute(0, 3, 2, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
