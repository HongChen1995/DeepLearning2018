{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn \n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input 100 Hz: 316x28x50\n",
      "Train target 100 Hz: 316\n",
      "Test input 100 Hz: 100x28x50\n",
      "Test target 100 Hz: 100\n",
      "\n",
      "Train input 1000 Hz: 316x28x500\n",
      "Train target 1000 Hz: 316\n",
      "Test input 1000 Hz: 100x28x500\n",
      "Test target 1000 Hz: 100\n"
     ]
    }
   ],
   "source": [
    "import dlc_bci\n",
    "\n",
    "train_input_100 , train_target_100 = dlc_bci.load(root = './data_bci_100Hz', download = False)\n",
    "test_input_100 , test_target_100 = dlc_bci.load(root = './data_bci_100Hz', download = False, train = False)\n",
    "\n",
    "train_input_1000 , train_target_1000 = dlc_bci.load(root = './data_bci_1000Hz', download = False, one_khz = True)\n",
    "test_input_1000 , test_target_1000 = dlc_bci.load(root = './data_bci_1000Hz', download = False, train = False, one_khz = True)\n",
    "\n",
    "print(\"Train input 100 Hz: {:d}x{:d}x{:d}\".format(*(s for s in train_input_100.size())))\n",
    "print(\"Train target 100 Hz: {:d}\".format(*(s for s in train_target_100.size())))\n",
    "print(\"Test input 100 Hz: {:d}x{:d}x{:d}\".format(*(s for s in test_input_100.size())))\n",
    "print(\"Test target 100 Hz: {:d}\".format(*(s for s in test_target_100.size())))\n",
    "print(\"\")\n",
    "print(\"Train input 1000 Hz: {:d}x{:d}x{:d}\".format(*(s for s in train_input_1000.size())))\n",
    "print(\"Train target 1000 Hz: {:d}\".format(*(s for s in train_target_1000.size())))\n",
    "print(\"Test input 1000 Hz: {:d}x{:d}x{:d}\".format(*(s for s in test_input_1000.size())))\n",
    "print(\"Test target 1000 Hz: {:d}\".format(*(s for s in test_target_1000.size())))\n",
    "\n",
    "Ntrain = train_input_100.size(0)\n",
    "Ntest = test_input_100.size(0)\n",
    "Nchannels = train_input_100.size(1)\n",
    "Nsamples_100 = train_input_100.size(-1)\n",
    "Nsamples_1000 = train_input_1000.size(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augementation & Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we take the 1000 hz signal and we subsample it with different time steps we downsample to 100Hz but with different initial points. By ding so we have 10 times more samples instead of having ones big weigth for the 1000hz sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_train(train_input, denoize = False, addGaussianNoise=False):\n",
    "    \n",
    "    #denoise and normalize data (without detrending and so)\n",
    "    tmp = np.array(train_input)\n",
    "    \n",
    "    if denoize:\n",
    "        tmp = denoisedSignals(tmp) #Deletes the high frequencies \n",
    "\n",
    "    #we take the 1000 hz signal and we subsample it with different time steps we downsample to 100Hz but with different initial points. By ding so we have 10 times more samples instead of having ones big weigth for the 1000hz sample\n",
    "\n",
    "    for i in range(9): \n",
    "        augmented_train_input = tmp[:,:,i::10]\n",
    "        idxToDelete = np.random.choice(range(len(augmented_train_input_0[:,0,0])), 16) #takes 16 lines as a validation set\n",
    "        augmented_train_input_validation = tmp[idxToDelete,:,0::10]\n",
    "        augmented_train_input_train = np.delete(augmented_train_input, idxToDelete, 0)\n",
    "        final_augmented_train_input_train = np.concatenate((final_augmented_train_input_train, augmented_train_input_train))\n",
    "        final_augmented_train_input_validation = np.concatenate((final_augmented_train_input_validation, augmented_train_input_validation))\n",
    "\n",
    "    if(addGaussianNoise):\n",
    "        noise_tensor = np.zeros(train_input.shape)\n",
    "        for i in range (augmented_train_input_train.shape[0]):\n",
    "            noiseIntensity = 0.1*np.max(augmented_train_input_train[i,:,:])\n",
    "            noise_tensor[i , :, :] = noise(augmented_train_input_train[i,:,:], noiseIntensity)\n",
    "        return noise_tensor, final_augmented_train_input_validation\n",
    "    \n",
    "    return final_augmented_train_input_train, final_augmented_train_input_validation\n",
    "\n",
    "def preprocessing_test(test_input, denoize = False):\n",
    "    #denoise and normalize data (without detrending and so)\n",
    "    tmp = np.array(test_input)\n",
    "    if denoize:\n",
    "        tmp = denoisedSignals(tmp)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[225 218 176 232  99 193 163 150 223 284 203 215 259  98  96  61]\n",
      "(300, 28, 50)\n",
      "(16, 28, 50)\n"
     ]
    }
   ],
   "source": [
    "h = preprocessing_train(train_input_1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 11\n",
    "Nchannels = 28\n",
    "Nsamples = 50\n",
    "x = Tensor(batch_size, Nchannels, Nsamples, 1).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Layer 1\n",
    "l1_channels = 16  \n",
    "conv1 = nn.Conv2d(1, l1_channels, (Nchannels, 1), padding = 0)\n",
    "batchnorm1 = nn.BatchNorm2d(l1_channels, False) # final size bsize x 1 x l1_channels x Nsamples\n",
    "\n",
    "# Layer 2\n",
    "l2_channels = 4\n",
    "l2_temp_window = 32\n",
    "l2_l1channel_overlap = 2\n",
    "padding1 = nn.ZeroPad2d((l2_temp_window // 2, l2_temp_window // 2 - 1, l2_l1channel_overlap//2-1, l2_l1channel_overlap//2)) # left, right, top, bottom\n",
    "conv2 = nn.Conv2d(1, l2_channels, (l2_l1channel_overlap, l2_temp_window))  # does not change size if combined with above padding\n",
    "batchnorm2 = nn.BatchNorm2d(l2_channels, False)\n",
    "pooling2 = nn.MaxPool2d((2, 4)) # final size bsize x l2_channels x floor(l1_channels/2) x floor(Nsamples/4)\n",
    "\n",
    "# Layer 3\n",
    "l3_channels = 4\n",
    "l3_temp_window = 4\n",
    "l3_l2channel_overlap = 8\n",
    "padding2 = nn.ZeroPad2d((l3_temp_window//2, l3_temp_window//2-1, l3_l2channel_overlap//2, l3_l2channel_overlap//2-1))\n",
    "conv3 = nn.Conv2d(l2_channels, l3_channels, (l3_l2channel_overlap, l3_temp_window))\n",
    "batchnorm3 = nn.BatchNorm2d(l3_channels, False)\n",
    "pooling3 = nn.MaxPool2d((2, 4)) # final size bsize x l3_channels x floor(l1_channels/4) x floor(Nsamples/16)\n",
    "\n",
    "# FC Layer\n",
    "fc_inputs = l3_channels * (l1_channels//4) * (Nsamples//16)\n",
    "fc1 = nn.Linear(fc_inputs, 1)\n",
    "\n",
    "# Forward pass: input size= (bsize,Nchannels, Nsamples, 1)\n",
    "x = Variable(x)\n",
    "x = x.permute(0, 3, 1, 2)   # bsize x 1 x Nchannels x Nsamples\n",
    "# Layer 1\n",
    "x = F.relu(conv1(x))         # bsize x l1_channels x 1 x Nsamples\n",
    "x = batchnorm1(x)\n",
    "x = F.dropout(x, 0.25)\n",
    "x = x.permute(0, 2, 1, 3)   # bsize x 1 x l1_channels x Nsamples\n",
    "print(\"Layer 1 output has size: \", x.shape)\n",
    "# Layer 2\n",
    "x = padding1(x)\n",
    "x = F.relu(conv2(x))    # bsize x l2_channels x l1_channels x Nsamples\n",
    "x = batchnorm2(x)       \n",
    "x = F.dropout(x, 0.25)\n",
    "x = pooling2(x)             # bsize x l2_channels x floor(l1_channels/2) x floor(Nsamples/4)\n",
    "print(\"Layer 2 output has size:\", x.shape)\n",
    "# Layer 3\n",
    "x = padding2(x)\n",
    "x = F.relu(conv3(x))         # bsize x l3_channels x floor(l1_channels/2) x floor(Nsamples/4)\n",
    "x = batchnorm3(x)\n",
    "x = F.dropout(x, 0.25)\n",
    "x = pooling3(x)             # bsize x l3_channels x floor(l1_channels/4) x floor(Nsamples/16)\n",
    "print(\"Layer 3 output has size:\", x.shape)\n",
    "# FC Layer\n",
    "x = x.view(-1, fc_inputs)   # bsize x (l3_channels*floor(l1_channels/4)*floor(Nsamples/16))\n",
    "x = F.sigmoid(fc1(x))\n",
    "print(\"Network output has size:\", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, Nchannels, Nsamples, output_units):\n",
    "        \"\"\"Initializes neural network with 3 convolutional layers and 1 fully-connected layer.\n",
    "        \n",
    "        Args:\n",
    "            - Nchannels (int): number of EEG channels\n",
    "            - Nsamples (int): number of time points in each EEG signal\n",
    "            - output_units (int): number of output units, e.g. 1 for training with loss torch.nn.BCELoss or 2 with \n",
    "            loss torch.nn.CrossEntropyLoss            \n",
    "            \n",
    "            \"\"\"\n",
    "        super(conv2DNet, self).__init__()\n",
    "        # Layer 1\n",
    "        l1_channels = 16  \n",
    "        self.conv1 = nn.Conv2d(1, l1_channels, (Nchannels, 1), padding = 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(l1_channels, False) # final size bsize x 1 x l1_channels x Nsamples\n",
    "\n",
    "        # Layer 2\n",
    "        l2_channels = 4\n",
    "        l2_temp_window = 32\n",
    "        l2_l1channel_overlap = 2\n",
    "        self.padding1 = nn.ZeroPad2d((l2_temp_window // 2, l2_temp_window // 2 - 1, l2_l1channel_overlap//2-1, l2_l1channel_overlap//2)) # left, right, top, bottom\n",
    "        self.conv2 = nn.Conv2d(1, l2_channels, (l2_l1channel_overlap, l2_temp_window))  # does not change size if combined with above padding\n",
    "        self.batchnorm2 = nn.BatchNorm2d(l2_channels, False)\n",
    "        self.pooling2 = nn.MaxPool2d((2, 4)) # final size bsize x l2_channels x floor(l1_channels/2) x floor(Nsamples/4)\n",
    "\n",
    "        # Layer 3\n",
    "        l3_channels = 4\n",
    "        l3_temp_window = 4\n",
    "        l3_l2channel_overlap = 8\n",
    "        self.padding2 = nn.ZeroPad2d((l3_temp_window//2, l3_temp_window//2-1, l3_l2channel_overlap//2, l3_l2channel_overlap//2-1))\n",
    "        self.conv3 = nn.Conv2d(l2_channels, l3_channels, (l3_l2channel_overlap, l3_temp_window))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(l3_channels, False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4)) # final size bsize x l3_channels x floor(l1_channels/4) x floor(Nsamples/16)\n",
    "\n",
    "        # FC Layer\n",
    "        fc_inputs = l3_channels * (l1_channels//4) * (Nsamples//16)\n",
    "        self.fc1 = nn.Linear(fc_inputs, output_units)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Applies forward pass consisting of 3 convolutional layers followed by a fully-connected linear layer.\n",
    "        \n",
    "        Args:\n",
    "            - x (torch.autograd.Variable): the input batch. It has dimension batch_size x Nchannel x Nsamples x 1,\n",
    "            where Nchannel is the number of EEG channels and Nsamples the number of time points.\n",
    "        \n",
    "        Returns:\n",
    "            - (torch.autograd.Variable) of size either batch_size x output_units   \n",
    "        \n",
    "        \"\"\"\n",
    "        x = x.permute(0, 3, 1, 2)             # bsize x 1 x Nchannels x Nsamples\n",
    "        \n",
    "        # Layer 1\n",
    "        x = F.elu(self.conv1(x))              # bsize x l1_channels x 1 x Nsamples\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.7)\n",
    "        x = x.permute(0, 2, 1, 3)             # bsize x 1 x l1_channels x Nsamples\n",
    "\n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = F.elu(self.conv2(x))              # bsize x l2_channels x l1_channels x Nsamples\n",
    "        x = self.batchnorm2(x)       \n",
    "        x = F.dropout(x, 0.7)\n",
    "        x = self.pooling2(x)                  # bsize x l2_channels x floor(l1_channels/2) x floor(Nsamples/4)\n",
    "\n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.elu(self.conv3(x))              # bsize x l3_channels x floor(l1_channels/2) x floor(Nsamples/4)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, 0.7)\n",
    "        x = self.pooling3(x)                  # bsize x l3_channels x floor(l1_channels/4) x floor(Nsamples/16)\n",
    "\n",
    "        # Fully-connected Layer\n",
    "        x = x.view(-1, self.fc1.in_features)  # bsize x (l3_channels*floor(l1_channels/4)*floor(Nsamples/16))\n",
    "        x = F.sigmoid(self.fc1(x))            # bisze x self.fc1.out_features  \n",
    "        \n",
    "        if self.fc1.out_features == 1:\n",
    "            x = x.view(-1)                     # bsize (1D if 1 output unit)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def compute_nb_errors(model, data_input, data_target):\n",
    "    batch_size = 35  # not as crucial as in training. Just a matter of memory.\n",
    "    nb_errors = 0\n",
    "    Ndata = data_input.size(0)\n",
    "    for b_start in range(0, data_input.size(0), batch_size):\n",
    "        bsize_eff = batch_size - max(0, b_start+batch_size-Ndata)  # boundary case\n",
    "        batch_output = model.forward(data_input.narrow(0, b_start, bsize_eff))  # is Variable if data_input is Variable\n",
    "        if len(list(batch_output.size()))>1 and batch_output.size(1) > 1:\n",
    "            # as many ouputs as there are classes => select maximum output\n",
    "            nb_err_batch = (batch_output.max(1)[1] != data_target.narrow(0, b_start, bsize_eff)).long().sum()\n",
    "            # overflow problem if conversion to Long Int not performed, treated as short 1-byte int otherwise!!\n",
    "        else:\n",
    "            # output is a scalar in [0, 1]\n",
    "            nb_err_batch = batch_output.round().sub(data_target.narrow(0, b_start, bsize_eff)).sign().abs().sum()\n",
    "        \n",
    "        nb_errors += nb_err_batch\n",
    "    if isinstance(nb_errors, Variable):\n",
    "        nb_errors = nb_errors.data[0]\n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network training and testing\n",
    "Non-linearity: elu  \n",
    "\n",
    "\n",
    "|criterion | optimizer | lr  | momentum | batch size | Nepochs | Train acc. | Test acc.|\n",
    "|----------|-----------|-----|----------|------------|---------|------------|----------|\n",
    "| BCE  | Adam  |1e-1 | def. | 15 | 150 | 86.4 | 61.4 | \n",
    "| BCE  | Adam  |1e-1 | def. | 20 | 150 | 99.8 | 79.5 | \n",
    "| BCE  | SGD   | 1e-2 | 0.85 | 20 | 150 | 98.9  | 61.5 | \n",
    "| CE   | Adam  | 1e-2 | def. | 20 | 150 | 98.4  |  70.5 | \n",
    "| CE   | SGD   | 1e-2 | 0.85 | 20 | 150 | 99.1 | 75.1 |\n",
    "\n",
    "\n",
    "Non-linearity: ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import math\n",
    "import numpy as np\n",
    "from utility import * \n",
    "\n",
    "preprocessed_input_train = preprocessing_train(train_input_1000)\n",
    "\n",
    "labels_input = train_target_100 #y_train\n",
    "labels = labels_input\n",
    "for i in range(9): \n",
    "    labels = np.concatenate((np.array(labels), np.array(labels_input)), axis = 0)\n",
    "\n",
    "labels = torch.from_numpy(labels)\n",
    "preprocessed_input_train = torch.from_numpy(preprocessed_input_train).float()\n",
    "\n",
    "Ntrain = len(preprocessed_input_train[:,0,0])\n",
    "print(Ntrain)\n",
    "\n",
    "train_input = Variable(preprocessed_input_train.view(Ntrain, Nchannels, Nsamples_100, 1))\n",
    "test_input = Variable(test_input_100.view(Ntest, Nchannels, Nsamples_100, 1))\n",
    "\n",
    "# Train network \n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "if isinstance(criterion, nn.BCELoss):\n",
    "    train_target = Variable(labels.float()) # convert to float\n",
    "    test_target = Variable(test_target_100.float())\n",
    "    Noutputs = 1\n",
    "elif isinstance(criterion, nn.CrossEntropyLoss):\n",
    "    train_target = Variable(labels)  # keep long tensors\n",
    "    test_target = Variable(test_target_100)\n",
    "    Noutputs = 2\n",
    "        \n",
    "model = conv2DNet(Nchannels, Nsamples_100, Noutputs)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1, momentum=0.90, nesterov=False)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-1)\n",
    "batch_size = 20\n",
    "Nbatches = int(math.ceil(Ntrain/batch_size))\n",
    "Nepochs = 200\n",
    "Nrep = 1\n",
    "train_errors = torch.Tensor(Nrep).zero_()\n",
    "test_errors = torch.Tensor(Nrep).zero_()\n",
    "\n",
    "for i_rep in range(Nrep):\n",
    "    for i_ep in range(Nepochs):\n",
    "        ep_loss = 0.0\n",
    "        for b_start in range(0, Ntrain, batch_size):\n",
    "            bsize_eff = batch_size - max(0, b_start+batch_size-Ntrain)  # boundary case\n",
    "            output = model(train_input.narrow(0, b_start, bsize_eff))\n",
    "            batch_loss = criterion(output, train_target.narrow(0, b_start, bsize_eff))\n",
    "            ep_loss += batch_loss.data[0]\n",
    "            model.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        nb_train_errs = compute_nb_errors(model, test_input, test_target)\n",
    "        #if i_ep % (Nepochs/20) == 0:\n",
    "            #print(\"Epoch {:d} running loss {}, {:d}/{:d} errors\".format(i_ep + 1, ep_loss, int(nb_train_errs), Ntrain))\n",
    "\n",
    "    nb_train_errs = compute_nb_errors(model, train_input, train_target)\n",
    "    # Evaluate on test data\n",
    "    nb_test_errs = compute_nb_errors(model, test_input, test_target)\n",
    "    print(\"Train accuracy {} Test accuracy {}\".format((Ntrain-nb_train_errs)/Ntrain, (Ntest-nb_test_errs)/Ntest))\n",
    "    train_errors[i_rep] = nb_train_errs\n",
    "    test_errors[i_rep] = nb_test_errs\n",
    "print(\"Training accuracy {:4.3g}%+-{}\".format(100*(Ntrain-train_errors.mean())/Ntrain, 100*train_errors.std()/Ntrain))\n",
    "print(\"Test accuracy {:4.3g}%+-{}\".format(100*(Ntest-test_errors.mean())/Ntest, 100*test_errors.std()/Ntest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
