{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn \n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input 100 Hz: 316x28x50\n",
      "Train target 100 Hz: 316\n",
      "Test input 100 Hz: 100x28x50\n",
      "Test target 100 Hz: 100\n",
      "\n",
      "Train input 1000 Hz: 316x28x500\n",
      "Train target 1000 Hz: 316\n",
      "Test input 1000 Hz: 100x28x500\n",
      "Test target 1000 Hz: 100\n"
     ]
    }
   ],
   "source": [
    "import dlc_bci\n",
    "\n",
    "train_input_100 , train_target_100 = dlc_bci.load(root = './data_bci_100Hz', download = False)\n",
    "test_input_100 , test_target_100 = dlc_bci.load(root = './data_bci_100Hz', download = False, train = False)\n",
    "\n",
    "train_input_1000 , train_target_1000 = dlc_bci.load(root = './data_bci_1000Hz', download = False, one_khz = True)\n",
    "test_input_1000 , test_target_1000 = dlc_bci.load(root = './data_bci_1000Hz', download = False, train = False, one_khz = True)\n",
    "\n",
    "print(\"Train input 100 Hz: {:d}x{:d}x{:d}\".format(*(s for s in train_input_100.size())))\n",
    "print(\"Train target 100 Hz: {:d}\".format(*(s for s in train_target_100.size())))\n",
    "print(\"Test input 100 Hz: {:d}x{:d}x{:d}\".format(*(s for s in test_input_100.size())))\n",
    "print(\"Test target 100 Hz: {:d}\".format(*(s for s in test_target_100.size())))\n",
    "print(\"\")\n",
    "print(\"Train input 1000 Hz: {:d}x{:d}x{:d}\".format(*(s for s in train_input_1000.size())))\n",
    "print(\"Train target 1000 Hz: {:d}\".format(*(s for s in train_target_1000.size())))\n",
    "print(\"Test input 1000 Hz: {:d}x{:d}x{:d}\".format(*(s for s in test_input_1000.size())))\n",
    "print(\"Test target 1000 Hz: {:d}\".format(*(s for s in test_target_1000.size())))\n",
    "\n",
    "Ntrain = train_input_100.size(0)\n",
    "Ntest = test_input_100.size(0)\n",
    "Nchannels = train_input_100.size(1)\n",
    "Nsamples_100 = train_input_100.size(-1)\n",
    "Nsamples_1000 = train_input_1000.size(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 11\n",
    "Nchannels = 28\n",
    "Nsamples = 50\n",
    "x = Tensor(batch_size, Nchannels, Nsamples, 1).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 28, 50, 1])\n",
      "Layer 1 output has size:  torch.Size([11, 1, 16, 50])\n",
      "Layer 2 output has size: torch.Size([11, 7, 8, 12])\n",
      "Layer 3 output has size: torch.Size([11, 4, 4, 3])\n",
      "Network output has size: torch.Size([11, 1])\n"
     ]
    }
   ],
   "source": [
    "# Layer 1\n",
    "l1_channels = 16  \n",
    "conv1 = nn.Conv2d(1, l1_channels, (Nchannels, 1), padding = 0)\n",
    "batchnorm1 = nn.BatchNorm2d(l1_channels, False) # final size bsize x 1 x l1_channels x Nsamples\n",
    "\n",
    "# Layer 2\n",
    "l2_channels = 4\n",
    "l2_temp_window = 32\n",
    "l2_l1channel_overlap = 2\n",
    "padding1 = nn.ZeroPad2d((l2_temp_window // 2, l2_temp_window // 2 - 1, l2_l1channel_overlap//2-1, l2_l1channel_overlap//2)) # left, right, top, bottom\n",
    "conv2 = nn.Conv2d(1, l2_channels, (l2_l1channel_overlap, l2_temp_window))  # does not change size if combined with above padding\n",
    "batchnorm2 = nn.BatchNorm2d(l2_channels, False)\n",
    "pooling2 = nn.MaxPool2d((2, 4)) # final size bsize x l2_channels x floor(l1_channels/2) x floor(Nsamples/4)\n",
    "\n",
    "# Layer 3\n",
    "l3_channels = 4\n",
    "l3_temp_window = 4\n",
    "l3_l2channel_overlap = 8\n",
    "padding2 = nn.ZeroPad2d((l3_temp_window//2, l3_temp_window//2-1, l3_l2channel_overlap//2, l3_l2channel_overlap//2-1))\n",
    "conv3 = nn.Conv2d(l2_channels, l3_channels, (l3_l2channel_overlap, l3_temp_window))\n",
    "batchnorm3 = nn.BatchNorm2d(l3_channels, False)\n",
    "pooling3 = nn.MaxPool2d((2, 4)) # final size bsize x l3_channels x floor(l1_channels/4) x floor(Nsamples/16)\n",
    "\n",
    "# FC Layer\n",
    "fc_inputs = l3_channels * (l1_channels//4) * (Nsamples//16)\n",
    "fc1 = nn.Linear(fc_inputs, 1)\n",
    "\n",
    "# Forward pass: input size= (bsize,Nchannels, Nsamples, 1)\n",
    "x = Variable(x)\n",
    "x = x.permute(0, 3, 1, 2)   # bsize x 1 x Nchannels x Nsamples\n",
    "# Layer 1\n",
    "x = F.elu(conv1(x))         # bsize x l1_channels x 1 x Nsamples\n",
    "x = batchnorm1(x)\n",
    "x = F.dropout(x, 0.25)\n",
    "x = x.permute(0, 2, 1, 3)   # bsize x 1 x l1_channels x Nsamples\n",
    "print(\"Layer 1 output has size: \", x.shape)\n",
    "# Layer 2\n",
    "x = padding1(x)\n",
    "x = F.elu(conv2(x))    # bsize x l2_channels x l1_channels x Nsamples\n",
    "x = batchnorm2(x)       \n",
    "x = F.dropout(x, 0.25)\n",
    "x = pooling2(x)             # bsize x l2_channels x floor(l1_channels/2) x floor(Nsamples/4)\n",
    "print(\"Layer 2 output has size:\", x.shape)\n",
    "# Layer 3\n",
    "x = padding2(x)\n",
    "x = F.elu(conv3(x))         # bsize x l3_channels x floor(l1_channels/2) x floor(Nsamples/4)\n",
    "x = batchnorm3(x)\n",
    "x = F.dropout(x, 0.25)\n",
    "x = pooling3(x)             # bsize x l3_channels x floor(l1_channels/4) x floor(Nsamples/16)\n",
    "print(\"Layer 3 output has size:\", x.shape)\n",
    "# FC Layer\n",
    "x = x.view(-1, fc_inputs)   # bsize x (l3_channels*floor(l1_channels/4)*floor(Nsamples/16))\n",
    "x = F.sigmoid(fc1(x))\n",
    "print(\"Network output has size:\", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, Nchannels, Nsamples, output_units):\n",
    "        \"\"\"Initializes neural network with 3 convolutional layers and 1 fully-connected layer.\n",
    "        \n",
    "        Args:\n",
    "            - Nchannels (int): number of EEG channels\n",
    "            - Nsamples (int): number of time points in each EEG signal\n",
    "            - output_units (int): number of output units, e.g. 1 for training with loss torch.nn.BCELoss or 2 with \n",
    "            loss torch.nn.CrossEntropyLoss            \n",
    "            \n",
    "            \"\"\"\n",
    "        super(conv2DNet, self).__init__()\n",
    "        # Layer 1\n",
    "        l1_channels = 16  \n",
    "        self.conv1 = nn.Conv2d(1, l1_channels, (Nchannels, 1), padding = 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(l1_channels, False) # final size bsize x 1 x l1_channels x Nsamples\n",
    "\n",
    "        # Layer 2\n",
    "        l2_channels = 4\n",
    "        l2_temp_window = 32\n",
    "        l2_l1channel_overlap = 2\n",
    "        self.padding1 = nn.ZeroPad2d((l2_temp_window // 2, l2_temp_window // 2 - 1, l2_l1channel_overlap//2-1, l2_l1channel_overlap//2)) # left, right, top, bottom\n",
    "        self.conv2 = nn.Conv2d(1, l2_channels, (l2_l1channel_overlap, l2_temp_window))  # does not change size if combined with above padding\n",
    "        self.batchnorm2 = nn.BatchNorm2d(l2_channels, False)\n",
    "        self.pooling2 = nn.MaxPool2d((2, 4)) # final size bsize x l2_channels x floor(l1_channels/2) x floor(Nsamples/4)\n",
    "\n",
    "        # Layer 3\n",
    "        l3_channels = 4\n",
    "        l3_temp_window = 4\n",
    "        l3_l2channel_overlap = 8\n",
    "        self.padding2 = nn.ZeroPad2d((l3_temp_window//2, l3_temp_window//2-1, l3_l2channel_overlap//2, l3_l2channel_overlap//2-1))\n",
    "        self.conv3 = nn.Conv2d(l2_channels, l3_channels, (l3_l2channel_overlap, l3_temp_window))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(l3_channels, False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4)) # final size bsize x l3_channels x floor(l1_channels/4) x floor(Nsamples/16)\n",
    "\n",
    "        # FC Layer\n",
    "        fc_inputs = l3_channels * (l1_channels//4) * (Nsamples//16)\n",
    "        self.fc1 = nn.Linear(fc_inputs, output_units)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Applies forward pass consisting of 3 convolutional layers followed by a fully-connected linear layer.\n",
    "        \n",
    "        Args:\n",
    "            - x (torch.autograd.Variable): the input batch. It has dimension batch_size x Nchannel x Nsamples x 1,\n",
    "            where Nchannel is the number of EEG channels and Nsamples the number of time points.\n",
    "        \n",
    "        Returns:\n",
    "            - (torch.autograd.Variable) of size either batch_size x output_units   \n",
    "        \n",
    "        \"\"\"\n",
    "        x = x.permute(0, 3, 1, 2)             # bsize x 1 x Nchannels x Nsamples\n",
    "        \n",
    "        # Layer 1\n",
    "        x = F.relu(self.conv1(x))              # bsize x l1_channels x 1 x Nsamples\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = x.permute(0, 2, 1, 3)             # bsize x 1 x l1_channels x Nsamples\n",
    "\n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = F.relu(self.conv2(x))              # bsize x l2_channels x l1_channels x Nsamples\n",
    "        x = self.batchnorm2(x)       \n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling2(x)                  # bsize x l2_channels x floor(l1_channels/2) x floor(Nsamples/4)\n",
    "\n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.relu(self.conv3(x))              # bsize x l3_channels x floor(l1_channels/2) x floor(Nsamples/4)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling3(x)                  # bsize x l3_channels x floor(l1_channels/4) x floor(Nsamples/16)\n",
    "\n",
    "        # Fully-connected Layer\n",
    "        x = x.view(-1, self.fc1.in_features)  # bsize x (l3_channels*floor(l1_channels/4)*floor(Nsamples/16))\n",
    "        x = F.sigmoid(self.fc1(x))            # bisze x self.fc1.out_features  \n",
    "        \n",
    "        if self.fc1.out_features == 1:\n",
    "            x = x.view(-1)                     # bsize (1D if 1 output unit)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def compute_nb_errors(model, data_input, data_target):\n",
    "    batch_size = 35  # not as crucial as in training. Just a matter of memory.\n",
    "    nb_errors = 0\n",
    "    Ndata = data_input.size(0)\n",
    "    for b_start in range(0, data_input.size(0), batch_size):\n",
    "        bsize_eff = batch_size - max(0, b_start+batch_size-Ndata)  # boundary case\n",
    "        batch_output = model.forward(data_input.narrow(0, b_start, bsize_eff))  # is Variable if data_input is Variable\n",
    "        if len(list(batch_output.size()))>1 and batch_output.size(1) > 1:\n",
    "            # as many ouputs as there are classes => select maximum output\n",
    "            nb_err_batch = (batch_output.max(1)[1] != data_target.narrow(0, b_start, bsize_eff)).long().sum()\n",
    "            # overflow problem if conversion to Long Int not performed, treated as short 1-byte int otherwise!!\n",
    "        else:\n",
    "            # output is a scalar in [0, 1]\n",
    "            nb_err_batch = batch_output.round().sub(data_target.narrow(0, b_start, bsize_eff)).sign().abs().sum()\n",
    "        \n",
    "        nb_errors += nb_err_batch\n",
    "    if isinstance(nb_errors, Variable):\n",
    "        nb_errors = nb_errors.data[0]\n",
    "    return nb_errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network training and testing\n",
    "Non-linearity: elu  \n",
    "\n",
    "\n",
    "|criterion | optimizer | lr  | momentum | batch size | Nepochs | Train acc. | Test acc.|\n",
    "|----------|-----------|-----|----------|------------|---------|------------|----------|\n",
    "| BCE  | Adam  |1e-1 | def. | 15 | 150 | 86.4 | 61.4 | \n",
    "| BCE  | Adam  |1e-1 | def. | 20 | 150 | 99.8 | 79.5 | \n",
    "| BCE  | SGD   | 1e-2 | 0.85 | 20 | 150 | 98.9  | 61.5 | \n",
    "| CE   | Adam  | 1e-2 | def. | 20 | 150 | 98.4  |  70.5 | \n",
    "| CE   | SGD   | 1e-2 | 0.85 | 20 | 150 | 99.1 | 75.1 |\n",
    "\n",
    "\n",
    "Non-linearity: ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.9936708860759493 Test accuracy 0.73\n",
      "Train accuracy 0.9936708860759493 Test accuracy 0.72\n",
      "Train accuracy 0.9936708860759493 Test accuracy 0.72\n",
      "Train accuracy 0.9968354430379747 Test accuracy 0.72\n",
      "Train accuracy 0.9968354430379747 Test accuracy 0.71\n",
      "Train accuracy 0.9968354430379747 Test accuracy 0.72\n",
      "Train accuracy 0.9968354430379747 Test accuracy 0.71\n",
      "Train accuracy 0.9968354430379747 Test accuracy 0.71\n",
      "Train accuracy 0.9968354430379747 Test accuracy 0.71\n",
      "Train accuracy 0.9968354430379747 Test accuracy 0.69\n",
      "Training accuracy 99.6%+-0.15286262390495187\n",
      "Test accuracy 71.4%+-1.07496769977314\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import math\n",
    "\n",
    "train_input = Variable(train_input_100.view(Ntrain, Nchannels, Nsamples_100, 1))\n",
    "\n",
    "test_input = Variable(test_input_100.view(Ntest, Nchannels, Nsamples_100, 1))\n",
    "\n",
    "\n",
    "# Train network \n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "if isinstance(criterion, nn.BCELoss):\n",
    "    train_target = Variable(train_target_100.float()) # convert to float\n",
    "    test_target = Variable(test_target_100.float())\n",
    "    Noutputs = 1\n",
    "elif isinstance(criterion, nn.CrossEntropyLoss):\n",
    "    train_target = Variable(train_target_100)  # keep long tensors\n",
    "    test_target = Variable(test_target_100)\n",
    "    Noutputs = 2\n",
    "        \n",
    "model = conv2DNet(Nchannels, Nsamples_100, Noutputs)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1, momentum=0.90, nesterov=False)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-1)\n",
    "batch_size = 20\n",
    "Nbatches = int(math.ceil(Ntrain/batch_size))\n",
    "Nepochs = 150\n",
    "Nrep = 10\n",
    "train_errors = torch.Tensor(Nrep).zero_()\n",
    "test_errors = torch.Tensor(Nrep).zero_()\n",
    "\n",
    "for i_rep in range(Nrep):\n",
    "    for i_ep in range(Nepochs):\n",
    "        ep_loss = 0.0\n",
    "        for b_start in range(0, Ntrain, batch_size):\n",
    "            bsize_eff = batch_size - max(0, b_start+batch_size-Ntrain)  # boundary case\n",
    "            output = model(train_input.narrow(0, b_start, bsize_eff))\n",
    "            batch_loss = criterion(output, train_target.narrow(0, b_start, bsize_eff))\n",
    "            ep_loss += batch_loss.data[0]\n",
    "            model.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        nb_train_errs = compute_nb_errors(model, test_input, test_target)\n",
    "        #if i_ep % (Nepochs/20) == 0:\n",
    "            #print(\"Epoch {:d} running loss {}, {:d}/{:d} errors\".format(i_ep + 1, ep_loss, int(nb_train_errs), Ntrain))\n",
    "\n",
    "    nb_train_errs = compute_nb_errors(model, train_input, train_target)\n",
    "    # Evaluate on test data\n",
    "    nb_test_errs = compute_nb_errors(model, test_input, test_target)\n",
    "    print(\"Train accuracy {} Test accuracy {}\".format((Ntrain-nb_train_errs)/Ntrain, (Ntest-nb_test_errs)/Ntest))\n",
    "    train_errors[i_rep] = nb_train_errs\n",
    "    test_errors[i_rep] = nb_test_errs\n",
    "print(\"Training accuracy {:4.3g}%+-{}\".format(100*(Ntrain-train_errors.mean())/Ntrain, 100*train_errors.std()/Ntrain))\n",
    "print(\"Test accuracy {:4.3g}%+-{}\".format(100*(Ntest-test_errors.mean())/Ntest, 100*test_errors.std()/Ntest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (deeplearningepfl)",
   "language": "python",
   "name": "deeplearningepfl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
